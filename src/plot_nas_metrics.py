"""
NAS Metrics Visualization Tool

This script provides comprehensive visualization of NAS monitoring metrics collected
during training. It reads CSV files generated by NASMonitorCallback and creates
four types of plots:

1. Redundancy Over Time: Track how activation redundancy evolves during training
2. Correlation Analysis: Heatmap showing correlation patterns in activations
3. Dashboard View: Multi-panel overview of all metrics
4. Model Comparison: Compare metrics across different model configurations

Usage:
    # Single model analysis
    python src/plot_nas_metrics.py --csv logs/nas/nano_u_nas_metrics.csv --output plots/nano_u_analysis.png
    
    # Compare multiple models
    python src/plot_nas_metrics.py --compare logs/nas/nano_u_*.csv --output plots/comparison.png
    
    # Generate all plot types
    python src/plot_nas_metrics.py --csv logs/nas/nano_u_nas_metrics.csv --all --output-dir plots/
"""

import os
import sys
import argparse
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

# seaborn is optional - only used for enhanced styling if available
try:
    import seaborn as sns
    sns.set_style("whitegrid")
except ImportError:
    sns = None
from typing import List, Dict, Optional

# Ensure project root is importable
if __name__ == "__main__" and __package__ is None:
    sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))


def load_nas_metrics(csv_path: str) -> pd.DataFrame:
    """Load NAS metrics from CSV file and normalize column names."""
    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"CSV file not found: {csv_path}")
    
    df = pd.read_csv(csv_path)
    
    # Normalize column names for compatibility
    if 'mean_correlation' in df.columns and 'correlation_mean' not in df.columns:
        df['correlation_mean'] = df['mean_correlation']
    if 'correlation_mean' not in df.columns:
        # Add dummy column if neither exists
        df['correlation_mean'] = 0.0
    if 'correlation_std' not in df.columns:
        # Add dummy std column for plotting
        df['correlation_std'] = 0.0
    
    print(f"✓ Loaded {len(df)} metric records from {csv_path}")
    return df


def plot_redundancy_over_time(df: pd.DataFrame, output_path: str, model_name: str = "Model"):
    """
    Plot 1: Redundancy Over Time
    
    Shows how activation redundancy (trace/max_eigenvalue ratio) evolves during training.
    High redundancy indicates potential for dimensionality reduction.
    """
    fig, axes = plt.subplots(2, 1, figsize=(12, 8))
    fig.suptitle(f'{model_name}: NAS Redundancy Analysis Over Time', fontsize=16, fontweight='bold')
    
    # Plot 1: Redundancy score
    axes[0].plot(df['epoch'], df['redundancy_score'], marker='o', linewidth=2, markersize=4, color='#2E86AB')
    axes[0].set_ylabel('Redundancy Score', fontsize=12, fontweight='bold')
    axes[0].set_xlabel('Epoch', fontsize=12)
    axes[0].grid(True, alpha=0.3)
    axes[0].set_title('Activation Redundancy (lower = more efficient)', fontsize=11)
    
    # Add threshold line at 0.5 (common rule of thumb)
    axes[0].axhline(y=0.5, color='r', linestyle='--', alpha=0.5, label='Target threshold (0.5)')
    axes[0].legend()
    
    # Plot 2: Trace and Condition Number
    ax2 = axes[1]
    ax2.plot(df['epoch'], df['trace'], marker='s', linewidth=2, markersize=4, color='#A23B72', label='Trace')
    ax2.set_ylabel('Trace (sum of eigenvalues)', fontsize=12, fontweight='bold', color='#A23B72')
    ax2.set_xlabel('Epoch', fontsize=12)
    ax2.tick_params(axis='y', labelcolor='#A23B72')
    ax2.grid(True, alpha=0.3)
    
    # Secondary axis for condition number
    ax2_twin = ax2.twinx()
    ax2_twin.plot(df['epoch'], df['condition_number'], marker='^', linewidth=2, markersize=4, color='#F18F01', label='Condition Number')
    ax2_twin.set_ylabel('Condition Number (log scale)', fontsize=12, fontweight='bold', color='#F18F01')
    ax2_twin.tick_params(axis='y', labelcolor='#F18F01')
    ax2_twin.set_yscale('log')
    
    # Combine legends
    lines1, labels1 = ax2.get_legend_handles_labels()
    lines2, labels2 = ax2_twin.get_legend_handles_labels()
    ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper right')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"✓ Saved redundancy plot to {output_path}")
    plt.close()


def plot_correlation_analysis(df: pd.DataFrame, output_path: str, model_name: str = "Model"):
    """
    Plot 2: Correlation Analysis
    
    Visualizes the correlation coefficient distribution over training.
    Shows how features become more or less correlated.
    """
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    fig.suptitle(f'{model_name}: Activation Correlation Analysis', fontsize=16, fontweight='bold')
    
    # Plot 1: Correlation over time
    # Use mean_correlation from callback (no std available in simple mode)
    corr_col = 'mean_correlation' if 'mean_correlation' in df.columns else 'correlation_mean'
    axes[0].plot(df['epoch'], df[corr_col], marker='o', linewidth=2, markersize=4,
                 color='#06A77D', label='Mean Correlation')
    if 'correlation_std' in df.columns:
        axes[0].fill_between(df['epoch'],
                         df[corr_col] - df['correlation_std'],
                         df[corr_col] + df['correlation_std'],
                         alpha=0.3, color='#06A77D', label='±1 Std Dev')
    axes[0].set_ylabel('Correlation Coefficient', fontsize=12, fontweight='bold')
    axes[0].set_xlabel('Epoch', fontsize=12)
    axes[0].grid(True, alpha=0.3)
    axes[0].legend()
    axes[0].set_title('Mean Correlation Over Training', fontsize=11)
    
    # Plot 2: Distribution histogram for last epoch
    corr_col = 'mean_correlation' if 'mean_correlation' in df.columns else 'correlation_mean'
    last_mean = df[corr_col].iloc[-1]
    last_std = df.get('correlation_std', pd.Series([0.1])).iloc[-1] if 'correlation_std' in df.columns else 0.1
    
    # Simulate distribution for visualization (since we only have mean/std)
    simulated_corr = np.random.normal(last_mean, last_std, 1000)
    simulated_corr = np.clip(simulated_corr, -1, 1)  # Correlations must be in [-1, 1]
    
    axes[1].hist(simulated_corr, bins=50, color='#06A77D', alpha=0.7, edgecolor='black')
    axes[1].axvline(last_mean, color='red', linestyle='--', linewidth=2, label=f'Mean: {last_mean:.3f}')
    axes[1].set_xlabel('Correlation Coefficient', fontsize=12, fontweight='bold')
    axes[1].set_ylabel('Frequency', fontsize=12, fontweight='bold')
    axes[1].legend()
    axes[1].set_title(f'Correlation Distribution (Final Epoch)', fontsize=11)
    axes[1].grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"✓ Saved correlation analysis to {output_path}")
    plt.close()


def plot_dashboard(df: pd.DataFrame, output_path: str, model_name: str = "Model"):
    """
    Plot 3: Comprehensive Dashboard
    
    Multi-panel view showing all key metrics in one figure.
    """
    fig = plt.figure(figsize=(16, 10))
    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)
    fig.suptitle(f'{model_name}: NAS Monitoring Dashboard', fontsize=18, fontweight='bold')
    
    # Panel 1: Redundancy Score
    ax1 = fig.add_subplot(gs[0, :2])
    ax1.plot(df['epoch'], df['redundancy_score'], marker='o', linewidth=2, color='#2E86AB')
    ax1.axhline(y=0.5, color='r', linestyle='--', alpha=0.5)
    ax1.set_ylabel('Redundancy', fontsize=11, fontweight='bold')
    ax1.set_title('Redundancy Score Over Time', fontsize=12, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    
    # Panel 2: Summary Stats (Text)
    ax2 = fig.add_subplot(gs[0, 2])
    ax2.axis('off')
    stats_text = f"""
    SUMMARY STATISTICS
    {'='*25}
    
    Final Redundancy: {df['redundancy_score'].iloc[-1]:.4f}
    Mean Redundancy: {df['redundancy_score'].mean():.4f}
    
    Final Correlation: {df['correlation_mean'].iloc[-1]:.4f}
    Mean Correlation: {df['correlation_mean'].mean():.4f}
    
    Final Trace: {df['trace'].iloc[-1]:.2f}
    Final Condition #: {df['condition_number'].iloc[-1]:.2e}
    
    Total Epochs: {len(df)}
    """
    ax2.text(0.1, 0.5, stats_text, fontsize=10, family='monospace', 
             verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))
    
    # Panel 3: Trace
    ax3 = fig.add_subplot(gs[1, 0])
    ax3.plot(df['epoch'], df['trace'], marker='s', linewidth=2, color='#A23B72')
    ax3.set_ylabel('Trace', fontsize=11, fontweight='bold')
    ax3.set_xlabel('Epoch', fontsize=10)
    ax3.set_title('Covariance Trace', fontsize=11, fontweight='bold')
    ax3.grid(True, alpha=0.3)
    
    # Panel 4: Correlation Mean
    ax4 = fig.add_subplot(gs[1, 1])
    ax4.plot(df['epoch'], df['correlation_mean'], marker='o', linewidth=2, color='#06A77D')
    ax4.fill_between(df['epoch'], 
                     df['correlation_mean'] - df['correlation_std'],
                     df['correlation_mean'] + df['correlation_std'],
                     alpha=0.3, color='#06A77D')
    ax4.set_ylabel('Correlation', fontsize=11, fontweight='bold')
    ax4.set_xlabel('Epoch', fontsize=10)
    ax4.set_title('Mean Correlation (±std)', fontsize=11, fontweight='bold')
    ax4.grid(True, alpha=0.3)
    
    # Panel 5: Condition Number (log scale)
    ax5 = fig.add_subplot(gs[1, 2])
    ax5.plot(df['epoch'], df['condition_number'], marker='^', linewidth=2, color='#F18F01')
    ax5.set_ylabel('Condition Number', fontsize=11, fontweight='bold')
    ax5.set_xlabel('Epoch', fontsize=10)
    ax5.set_yscale('log')
    ax5.set_title('Condition Number (log)', fontsize=11, fontweight='bold')
    ax5.grid(True, alpha=0.3)
    
    # Panel 6: Redundancy Score Distribution
    ax6 = fig.add_subplot(gs[2, 0])
    ax6.hist(df['redundancy_score'], bins=20, color='#2E86AB', alpha=0.7, edgecolor='black')
    ax6.axvline(df['redundancy_score'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')
    ax6.set_xlabel('Redundancy Score', fontsize=10, fontweight='bold')
    ax6.set_ylabel('Frequency', fontsize=11, fontweight='bold')
    ax6.set_title('Redundancy Distribution', fontsize=11, fontweight='bold')
    ax6.legend()
    ax6.grid(True, alpha=0.3, axis='y')
    
    # Panel 7: Correlation Distribution
    ax7 = fig.add_subplot(gs[2, 1])
    ax7.hist(df['correlation_mean'], bins=20, color='#06A77D', alpha=0.7, edgecolor='black')
    ax7.axvline(df['correlation_mean'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')
    ax7.set_xlabel('Correlation', fontsize=10, fontweight='bold')
    ax7.set_ylabel('Frequency', fontsize=11, fontweight='bold')
    ax7.set_title('Correlation Distribution', fontsize=11, fontweight='bold')
    ax7.legend()
    ax7.grid(True, alpha=0.3, axis='y')
    
    # Panel 8: Training Progress
    ax8 = fig.add_subplot(gs[2, 2])
    # Normalized metrics for comparison (0-1 scale)
    norm_redundancy = (df['redundancy_score'] - df['redundancy_score'].min()) / (df['redundancy_score'].max() - df['redundancy_score'].min() + 1e-8)
    norm_correlation = (df['correlation_mean'] - df['correlation_mean'].min()) / (df['correlation_mean'].max() - df['correlation_mean'].min() + 1e-8)
    
    ax8.plot(df['epoch'], norm_redundancy, label='Redundancy (norm)', linewidth=2, color='#2E86AB')
    ax8.plot(df['epoch'], norm_correlation, label='Correlation (norm)', linewidth=2, color='#06A77D')
    ax8.set_ylabel('Normalized Value', fontsize=11, fontweight='bold')
    ax8.set_xlabel('Epoch', fontsize=10)
    ax8.set_title('Normalized Metrics', fontsize=11, fontweight='bold')
    ax8.legend()
    ax8.grid(True, alpha=0.3)
    
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"✓ Saved dashboard to {output_path}")
    plt.close()


def plot_model_comparison(csv_files: List[str], output_path: str):
    """
    Plot 4: Model Comparison
    
    Compare NAS metrics across different model configurations.
    """
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('Model Comparison: NAS Metrics', fontsize=16, fontweight='bold')
    
    colors = plt.cm.tab10(np.linspace(0, 1, len(csv_files)))
    
    for idx, csv_file in enumerate(csv_files):
        df = load_nas_metrics(csv_file)
        model_name = Path(csv_file).stem.replace('_nas_metrics', '')
        color = colors[idx]
        
        # Plot 1: Redundancy Score
        axes[0, 0].plot(df['epoch'], df['redundancy_score'], 
                       marker='o', linewidth=2, markersize=3, 
                       label=model_name, color=color, alpha=0.8)
        
        # Plot 2: Correlation Mean
        axes[0, 1].plot(df['epoch'], df['correlation_mean'], 
                       marker='s', linewidth=2, markersize=3,
                       label=model_name, color=color, alpha=0.8)
        
        # Plot 3: Trace
        axes[1, 0].plot(df['epoch'], df['trace'], 
                       marker='^', linewidth=2, markersize=3,
                       label=model_name, color=color, alpha=0.8)
        
        # Plot 4: Condition Number
        axes[1, 1].plot(df['epoch'], df['condition_number'], 
                       marker='d', linewidth=2, markersize=3,
                       label=model_name, color=color, alpha=0.8)
    
    # Configure subplots
    axes[0, 0].set_ylabel('Redundancy Score', fontsize=11, fontweight='bold')
    axes[0, 0].set_xlabel('Epoch', fontsize=10)
    axes[0, 0].set_title('Redundancy Comparison', fontsize=12, fontweight='bold')
    axes[0, 0].grid(True, alpha=0.3)
    axes[0, 0].legend()
    axes[0, 0].axhline(y=0.5, color='r', linestyle='--', alpha=0.3)
    
    axes[0, 1].set_ylabel('Mean Correlation', fontsize=11, fontweight='bold')
    axes[0, 1].set_xlabel('Epoch', fontsize=10)
    axes[0, 1].set_title('Correlation Comparison', fontsize=12, fontweight='bold')
    axes[0, 1].grid(True, alpha=0.3)
    axes[0, 1].legend()
    
    axes[1, 0].set_ylabel('Trace', fontsize=11, fontweight='bold')
    axes[1, 0].set_xlabel('Epoch', fontsize=10)
    axes[1, 0].set_title('Trace Comparison', fontsize=12, fontweight='bold')
    axes[1, 0].grid(True, alpha=0.3)
    axes[1, 0].legend()
    
    axes[1, 1].set_ylabel('Condition Number', fontsize=11, fontweight='bold')
    axes[1, 1].set_xlabel('Epoch', fontsize=10)
    axes[1, 1].set_yscale('log')
    axes[1, 1].set_title('Condition Number Comparison (log)', fontsize=12, fontweight='bold')
    axes[1, 1].grid(True, alpha=0.3)
    axes[1, 1].legend()
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"✓ Saved comparison plot to {output_path}")
    plt.close()


def generate_recommendations(df: pd.DataFrame, model_name: str = "Model") -> str:
    """
    Generate automated architecture recommendations based on NAS metrics.
    
    Returns formatted text with actionable insights.
    """
    final_redundancy = df['redundancy_score'].iloc[-1]
    mean_redundancy = df['redundancy_score'].mean()
    final_correlation = df['correlation_mean'].iloc[-1]
    final_condition = df['condition_number'].iloc[-1]
    
    recommendations = []
    recommendations.append(f"\n{'='*60}")
    recommendations.append(f"ARCHITECTURE RECOMMENDATIONS FOR {model_name.upper()}")
    recommendations.append(f"{'='*60}\n")
    
    # Redundancy analysis
    recommendations.append("1. REDUNDANCY ANALYSIS:")
    if final_redundancy > 0.7:
        recommendations.append(f"   ⚠️  HIGH REDUNDANCY (final={final_redundancy:.3f})")
        recommendations.append("   → Consider reducing bottleneck size or decoder filters")
        recommendations.append("   → High redundancy indicates wasted capacity")
    elif final_redundancy < 0.3:
        recommendations.append(f"   ✓ LOW REDUNDANCY (final={final_redundancy:.3f})")
        recommendations.append("   → Good feature utilization")
        recommendations.append("   → Current architecture is efficient")
    else:
        recommendations.append(f"   ℹ️  MODERATE REDUNDANCY (final={final_redundancy:.3f})")
        recommendations.append("   → Architecture is reasonably efficient")
        recommendations.append("   → Minor optimizations possible")
    
    # Correlation analysis
    recommendations.append("\n2. CORRELATION ANALYSIS:")
    if abs(final_correlation) > 0.5:
        recommendations.append(f"   ⚠️  HIGH CORRELATION (final={final_correlation:.3f})")
        recommendations.append("   → Features are highly correlated")
        recommendations.append("   → Consider adding dropout or reducing layer width")
    else:
        recommendations.append(f"   ✓ LOW CORRELATION (final={final_correlation:.3f})")
        recommendations.append("   → Features are diverse and independent")
    
    # Condition number analysis
    recommendations.append("\n3. NUMERICAL STABILITY:")
    if final_condition > 1e6:
        recommendations.append(f"   ⚠️  POOR CONDITIONING (final={final_condition:.2e})")
        recommendations.append("   → Risk of numerical instability")
        recommendations.append("   → Consider batch normalization or weight regularization")
    elif final_condition > 1e4:
        recommendations.append(f"   ℹ️  MODERATE CONDITIONING (final={final_condition:.2e})")
        recommendations.append("   → Acceptable numerical stability")
    else:
        recommendations.append(f"   ✓ GOOD CONDITIONING (final={final_condition:.2e})")
        recommendations.append("   → Excellent numerical stability")
    
    # Training dynamics
    recommendations.append("\n4. TRAINING DYNAMICS:")
    redundancy_trend = df['redundancy_score'].iloc[-5:].mean() - df['redundancy_score'].iloc[:5].mean()
    if redundancy_trend > 0.1:
        recommendations.append("   ℹ️  Redundancy INCREASING over training")
        recommendations.append("   → Model may be underfitting or overparameterized")
    elif redundancy_trend < -0.1:
        recommendations.append("   ✓ Redundancy DECREASING over training")
        recommendations.append("   → Model is learning efficient representations")
    else:
        recommendations.append("   ℹ️  Redundancy STABLE over training")
        recommendations.append("   → Consistent feature utilization")
    
    # Overall recommendation
    recommendations.append("\n5. OVERALL RECOMMENDATION:")
    if final_redundancy > 0.6 and abs(final_correlation) > 0.4:
        recommendations.append("   ⚠️  ARCHITECTURE NEEDS OPTIMIZATION")
        recommendations.append("   → Reduce model width or bottleneck size by 25-50%")
        recommendations.append("   → Add regularization (dropout, weight decay)")
    elif final_redundancy < 0.4 and abs(final_correlation) < 0.3:
        recommendations.append("   ✓ ARCHITECTURE IS WELL-OPTIMIZED")
        recommendations.append("   → Current design is efficient and well-utilized")
        recommendations.append("   → Focus on training hyperparameters if needed")
    else:
        recommendations.append("   ℹ️  ARCHITECTURE IS ACCEPTABLE")
        recommendations.append("   → Minor tweaks may improve efficiency")
        recommendations.append("   → Consider testing 10-20% capacity reduction")
    
    recommendations.append(f"\n{'='*60}\n")
    
    return "\n".join(recommendations)


def main():
    parser = argparse.ArgumentParser(description="Visualize NAS monitoring metrics")
    parser.add_argument("--csv", type=str, help="Path to single CSV file with NAS metrics")
    parser.add_argument("--compare", nargs='+', help="List of CSV files to compare")
    parser.add_argument("--output", type=str, help="Output path for single plot")
    parser.add_argument("--output-dir", type=str, help="Output directory for multiple plots")
    parser.add_argument("--all", action="store_true", help="Generate all plot types")
    parser.add_argument("--plot-type", choices=["redundancy", "correlation", "dashboard", "comparison"],
                       help="Specific plot type to generate")
    parser.add_argument("--model-name", type=str, default="Model", help="Model name for plot titles")
    parser.add_argument("--recommendations", action="store_true", help="Print architecture recommendations")
    
    args = parser.parse_args()
    
    # Validation
    if not args.csv and not args.compare:
        parser.error("Must provide either --csv or --compare")
    
    if args.compare and not args.output:
        parser.error("--compare requires --output")
    
    # Set output directory
    if args.output_dir:
        os.makedirs(args.output_dir, exist_ok=True)
        output_dir = args.output_dir
    else:
        output_dir = "plots"
        os.makedirs(output_dir, exist_ok=True)
    
    # Model comparison mode
    if args.compare:
        output_path = args.output if args.output else os.path.join(output_dir, "model_comparison.png")
        plot_model_comparison(args.compare, output_path)
        return
    
    # Single model analysis
    df = load_nas_metrics(args.csv)
    model_name = args.model_name
    
    if args.all:
        # Generate all plots
        plot_redundancy_over_time(df, os.path.join(output_dir, f"{model_name}_redundancy.png"), model_name)
        plot_correlation_analysis(df, os.path.join(output_dir, f"{model_name}_correlation.png"), model_name)
        plot_dashboard(df, os.path.join(output_dir, f"{model_name}_dashboard.png"), model_name)
        print(f"\n✓ Generated all plots in {output_dir}/")
    elif args.plot_type:
        output_path = args.output if args.output else os.path.join(output_dir, f"{model_name}_{args.plot_type}.png")
        
        if args.plot_type == "redundancy":
            plot_redundancy_over_time(df, output_path, model_name)
        elif args.plot_type == "correlation":
            plot_correlation_analysis(df, output_path, model_name)
        elif args.plot_type == "dashboard":
            plot_dashboard(df, output_path, model_name)
    else:
        # Default: generate dashboard
        output_path = args.output if args.output else os.path.join(output_dir, f"{model_name}_dashboard.png")
        plot_dashboard(df, output_path, model_name)
    
    # Generate recommendations if requested
    if args.recommendations:
        recommendations = generate_recommendations(df, model_name)
        print(recommendations)
        
        # Also save to file
        rec_path = os.path.join(output_dir, f"{model_name}_recommendations.txt")
        with open(rec_path, 'w') as f:
            f.write(recommendations)
        print(f"✓ Saved recommendations to {rec_path}")


if __name__ == "__main__":
    main()
