{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1095f99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/fefe/Projects/Nano-U/notebooks\n",
      "Python path includes: ['/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages', '/home/fefe/Projects/Nano-U', '/home/fefe/Projects/Nano-U', '/home/fefe/Projects/Nano-U', '/home/fefe/Projects/Nano-U', '/home/fefe/Projects/Nano-U']\n",
      "Notebook ready for retraining experiments\n"
     ]
    }
   ],
   "source": [
    "# Experiment Retraining Notebook for Nano-U Project\n",
    "# This notebook demonstrates various retraining experiments for Nano-U and BU-Net models\n",
    "\n",
    "# Setup project path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))))\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Python path includes: {[p for p in sys.path if 'Nano-U' in p]}\")\n",
    "\n",
    "# Import training API\n",
    "from src.train_tf import train_tf\n",
    "from src.infer_tf import infer_tf\n",
    "from src.utils.config import load_config\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print('Notebook ready for retraining experiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0ddb12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.21.0-dev20260109\n",
      "âœ“ GPU detected: 1 GPU(s) available\n",
      "  - /physical_device:GPU:0\n",
      "GPU training available!\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"âœ“ GPU detected: {len(gpus)} GPU(s) available\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"  - {gpu.name}\")\n",
    "    print(\"GPU training available!\")\n",
    "else:\n",
    "    print(\"âš  No GPU detected - using CPU (training will be slow)\")\n",
    "    print(\"Note: GPU support can be enabled later with compatible TensorFlow version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7922d1",
   "metadata": {},
   "source": [
    "# Nano-U Retraining Experiments\n",
    "\n",
    "This notebook provides examples for retraining the Nano-U and BU-Net models with different configurations, hyperparameters, and techniques like knowledge distillation.\n",
    "\n",
    "**Requirements:**\n",
    "- Python 3.12\n",
    "- TensorFlow nightly\n",
    "- NVIDIA GPU with CUDA 12.0+ (optional but recommended for faster training)\n",
    "\n",
    "**Current Status:**\n",
    "- âœ… CPU training: Fully functional\n",
    "- âš ï¸ GPU training: Limited support for RTX 50xx series with current TensorFlow versions\n",
    "- ðŸ”„ Data preparation: Working correctly\n",
    "\n",
    "## Table of Contents\n",
    "1. [Basic Training](#basic-training)\n",
    "2. [Custom Hyperparameters](#custom-hyperparameters)\n",
    "3. [BU-Net Training](#bu-net-training)\n",
    "4. [Knowledge Distillation](#knowledge-distillation)\n",
    "5. [Evaluation and Visualization](#evaluation)\n",
    "6. [Hyperparameter Tuning](#hyperparameter-tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bfc161",
   "metadata": {},
   "source": [
    "## 1. Basic Training\n",
    "\n",
    "Train the Nano-U model with default configuration from config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4cf278a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting basic Nano-U training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting basic Nano-U training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1768004813.347922  212882 gpu_device.cc:2459] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "I0000 00:00:1768004813.470922  212882 gpu_device.cc:2043] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5785 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5060 Laptop GPU, pci bus id: 0000:64:00.0, compute capability: 12.0a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting basic Nano-U training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1768004813.347922  212882 gpu_device.cc:2459] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "I0000 00:00:1768004813.470922  212882 gpu_device.cc:2043] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5785 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5060 Laptop GPU, pci bus id: 0000:64:00.0, compute capability: 12.0a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for nano_u...\n",
      "Epochs: 150, Batch Size: 16, LR: 0.0001, Distill: False\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting basic Nano-U training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1768004813.347922  212882 gpu_device.cc:2459] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "I0000 00:00:1768004813.470922  212882 gpu_device.cc:2043] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5785 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5060 Laptop GPU, pci bus id: 0000:64:00.0, compute capability: 12.0a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for nano_u...\n",
      "Epochs: 150, Batch Size: 16, LR: 0.0001, Distill: False\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1768004825.108418  223677 op_kernel.cc:1858] OP_REQUIRES failed at xla_ops.cc:540 : INVALID_ARGUMENT: Trying to access resource double_conv/depthwise_conv2d/kernel/2 (defined @ /home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:42) located in device /job:localhost/replica:0/task:0/device:CPU:0 from device /job:localhost/replica:0/task:0/device:GPU:0\n",
      " Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n",
      "W0000 00:00:1768004825.108471  223677 local_rendezvous.cc:412] Local rendezvous is aborting with status: INVALID_ARGUMENT: Trying to access resource double_conv/depthwise_conv2d/kernel/2 (defined @ /home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:42) located in device /job:localhost/replica:0/task:0/device:CPU:0 from device /job:localhost/replica:0/task:0/device:GPU:0\n",
      " Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting basic Nano-U training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1768004813.347922  212882 gpu_device.cc:2459] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "I0000 00:00:1768004813.470922  212882 gpu_device.cc:2043] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5785 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5060 Laptop GPU, pci bus id: 0000:64:00.0, compute capability: 12.0a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for nano_u...\n",
      "Epochs: 150, Batch Size: 16, LR: 0.0001, Distill: False\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1768004825.108418  223677 op_kernel.cc:1858] OP_REQUIRES failed at xla_ops.cc:540 : INVALID_ARGUMENT: Trying to access resource double_conv/depthwise_conv2d/kernel/2 (defined @ /home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:42) located in device /job:localhost/replica:0/task:0/device:CPU:0 from device /job:localhost/replica:0/task:0/device:GPU:0\n",
      " Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n",
      "W0000 00:00:1768004825.108471  223677 local_rendezvous.cc:412] Local rendezvous is aborting with status: INVALID_ARGUMENT: Trying to access resource double_conv/depthwise_conv2d/kernel/2 (defined @ /home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:42) located in device /job:localhost/replica:0/task:0/device:CPU:0 from device /job:localhost/replica:0/task:0/device:GPU:0\n",
      " Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 758, in start\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/home/fefe/.pyenv/versions/3.12.12/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n\n  File \"/home/fefe/.pyenv/versions/3.12.12/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n\n  File \"/home/fefe/.pyenv/versions/3.12.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3123, in run_cell\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3178, in _run_cell\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_cell_async\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3641, in run_ast_nodes\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3701, in run_code\n\n  File \"/tmp/ipykernel_212882/4269910414.py\", line 4, in <module>\n\n  File \"/home/fefe/Projects/Nano-U/src/train_tf.py\", line 294, in train_tf\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 399, in fit\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 241, in function\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 154, in multi_step_on_iterator\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 125, in wrapper\n\nTrying to access resource double_conv/depthwise_conv2d/kernel/2 (defined @ /home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:42) located in device /job:localhost/replica:0/task:0/device:CPU:0 from device /job:localhost/replica:0/task:0/device:GPU:0\n Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_18187]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Basic Nano-U Training\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting basic Nano-U training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model, history = \u001b[43mtrain_tf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnano_u\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfig/config.yaml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining completed!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Nano-U/src/train_tf.py:294\u001b[39m, in \u001b[36mtrain_tf\u001b[39m\u001b[34m(model_name, epochs, batch_size, lr, distill, teacher_weights, alpha, temperature, augment, config_path)\u001b[39m\n\u001b[32m    287\u001b[39m     callbacks = [\n\u001b[32m    288\u001b[39m         tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path, save_best_only=\u001b[38;5;28;01mTrue\u001b[39;00m, monitor=\u001b[33m\"\u001b[39m\u001b[33mval_binary_iou\u001b[39m\u001b[33m\"\u001b[39m, mode=\u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    289\u001b[39m         tf.keras.callbacks.ReduceLROnPlateau(monitor=\u001b[33m\"\u001b[39m\u001b[33mval_binary_iou\u001b[39m\u001b[33m\"\u001b[39m, mode=\u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m, factor=\u001b[32m0.5\u001b[39m, patience=\u001b[32m10\u001b[39m, min_lr=\u001b[32m1e-6\u001b[39m, verbose=\u001b[32m1\u001b[39m),\n\u001b[32m    290\u001b[39m         tf.keras.callbacks.EarlyStopping(monitor=\u001b[33m\"\u001b[39m\u001b[33mval_binary_iou\u001b[39m\u001b[33m\"\u001b[39m, mode=\u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m, patience=\u001b[32m20\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    291\u001b[39m     ]\n\u001b[32m    293\u001b[39m \u001b[38;5;66;03m# Unified Training Loop\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m final_path = os.path.join(models_dir, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_tf_final.keras\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m distill:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 758, in start\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/home/fefe/.pyenv/versions/3.12.12/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n\n  File \"/home/fefe/.pyenv/versions/3.12.12/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n\n  File \"/home/fefe/.pyenv/versions/3.12.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3123, in run_cell\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3178, in _run_cell\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_cell_async\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3641, in run_ast_nodes\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3701, in run_code\n\n  File \"/tmp/ipykernel_212882/4269910414.py\", line 4, in <module>\n\n  File \"/home/fefe/Projects/Nano-U/src/train_tf.py\", line 294, in train_tf\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 399, in fit\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 241, in function\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 154, in multi_step_on_iterator\n\n  File \"/home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 125, in wrapper\n\nTrying to access resource double_conv/depthwise_conv2d/kernel/2 (defined @ /home/fefe/Projects/Nano-U/.venv-tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:42) located in device /job:localhost/replica:0/task:0/device:CPU:0 from device /job:localhost/replica:0/task:0/device:GPU:0\n Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_18187]"
     ]
    }
   ],
   "source": [
    "# Basic Nano-U Training\n",
    "print(\"Starting basic Nano-U training...\")\n",
    "\n",
    "model, history = train_tf(\n",
    "    model_name=\"nano_u\",\n",
    "    config_path=\"config/config.yaml\"\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")\n",
    "print(f\"Model saved to: {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf29449e",
   "metadata": {},
   "source": [
    "## 2. Custom Hyperparameters\n",
    "\n",
    "Train with custom learning rate, batch size, and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d4bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Hyperparameters Training\n",
    "print(\"Training Nano-U with custom hyperparameters...\")\n",
    "\n",
    "model_custom, history_custom = train_tf(\n",
    "    model_name=\"nano_u\",\n",
    "    epochs=25,              # Override default epochs\n",
    "    batch_size=16,          # Larger batch size\n",
    "    lr=1e-3,               # Higher learning rate\n",
    "    config_path=\"config/config.yaml\"\n",
    ")\n",
    "\n",
    "print(\"Custom training completed!\")\n",
    "print(f\"Model saved to: {model_custom}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766b2d78",
   "metadata": {},
   "source": [
    "## 3. BU-Net Training\n",
    "\n",
    "Train the BU-Net model instead of Nano-U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71581cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BU-Net Training\n",
    "print(\"Training BU-Net model...\")\n",
    "\n",
    "bu_net_model, bu_net_history = train_tf(\n",
    "    model_name=\"bu_net\",\n",
    "    epochs=30,\n",
    "    batch_size=8,\n",
    "    lr=5e-4,\n",
    "    config_path=\"config/config.yaml\"\n",
    ")\n",
    "\n",
    "print(\"BU-Net training completed!\")\n",
    "print(f\"Model saved to: {bu_net_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f1f60",
   "metadata": {},
   "source": [
    "## 4. Knowledge Distillation\n",
    "\n",
    "Train Nano-U using knowledge distillation from a teacher model (BU-Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d56e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge Distillation Training\n",
    "print(\"Training Nano-U with knowledge distillation from BU-Net...\")\n",
    "\n",
    "distilled_model, distilled_history = train_tf(\n",
    "    model_name=\"nano_u\",\n",
    "    epochs=20,\n",
    "    distill=True,                    # Enable distillation\n",
    "    teacher_weights=\"models/bu_net_tf_final.keras\",  # Teacher model\n",
    "    alpha=0.7,                      # Balance between distillation and ground truth loss\n",
    "    temperature=3.0,                # Temperature for softening predictions\n",
    "    lr=1e-3,\n",
    "    config_path=\"config/config.yaml\"\n",
    ")\n",
    "\n",
    "print(\"Distillation training completed!\")\n",
    "print(f\"Distilled model saved to: {distilled_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70322b09",
   "metadata": {},
   "source": [
    "## 5. Evaluation and Visualization\n",
    "\n",
    "Evaluate trained models and visualize training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38decc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "print(\"Evaluating trained models...\")\n",
    "\n",
    "# Evaluate Nano-U model\n",
    "nano_u_preds = infer_tf(\n",
    "    model_name=\"nano_u\",\n",
    "    weights_path=\"models/nano_u_tf_final.keras\",\n",
    "    config_path=\"config/config.yaml\"\n",
    ")\n",
    "\n",
    "# Evaluate BU-Net model\n",
    "bu_net_preds = infer_tf(\n",
    "    model_name=\"bu_net\",\n",
    "    weights_path=\"models/bu_net_tf_final.keras\",\n",
    "    config_path=\"config/config.yaml\"\n",
    ")\n",
    "\n",
    "print(\"Evaluation completed!\")\n",
    "print(f\"Nano-U predictions shape: {nano_u_preds.shape if nano_u_preds is not None else 'None'}\")\n",
    "print(f\"BU-Net predictions shape: {bu_net_preds.shape if bu_net_preds is not None else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2469d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training History Visualization\n",
    "def plot_training_history(history, title):\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    # Loss\n",
    "    ax1.plot(history.history['loss'], label='Training Loss')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax1.set_title('Loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    # Binary IoU\n",
    "    ax2.plot(history.history['binary_iou'], label='Training IoU')\n",
    "    ax2.plot(history.history['val_binary_iou'], label='Validation IoU')\n",
    "    ax2.set_title('Binary IoU')\n",
    "    ax2.legend()\n",
    "\n",
    "    # Precision\n",
    "    if 'precision' in history.history:\n",
    "        ax3.plot(history.history['precision'], label='Training Precision')\n",
    "        ax3.plot(history.history['val_precision'], label='Validation Precision')\n",
    "        ax3.set_title('Precision')\n",
    "        ax3.legend()\n",
    "\n",
    "    # Recall\n",
    "    if 'recall' in history.history:\n",
    "        ax4.plot(history.history['recall'], label='Training Recall')\n",
    "        ax4.plot(history.history['val_recall'], label='Validation Recall')\n",
    "        ax4.set_title('Recall')\n",
    "        ax4.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot histories if available\n",
    "try:\n",
    "    if 'history' in locals():\n",
    "        plot_training_history(history, 'Basic Nano-U Training')\n",
    "except NameError:\n",
    "    print(\"Basic training history not available\")\n",
    "\n",
    "try:\n",
    "    if 'history_custom' in locals():\n",
    "        plot_training_history(history_custom, 'Custom Hyperparameters Training')\n",
    "except NameError:\n",
    "    print(\"Custom training history not available\")\n",
    "\n",
    "try:\n",
    "    if 'bu_net_history' in locals():\n",
    "        plot_training_history(bu_net_history, 'BU-Net Training')\n",
    "except NameError:\n",
    "    print(\"BU-Net training history not available\")\n",
    "\n",
    "try:\n",
    "    if 'distilled_history' in locals():\n",
    "        plot_training_history(distilled_history, 'Knowledge Distillation Training')\n",
    "except NameError:\n",
    "    print(\"Distillation training history not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6ee12c",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning\n",
    "\n",
    "Experiment with different learning rates and batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185831ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning Experiments\n",
    "learning_rates = [1e-4, 5e-4, 1e-3]\n",
    "batch_sizes = [8, 16, 32]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        print(f\"\\nTraining with LR={lr}, Batch Size={bs}\")\n",
    "        try:\n",
    "            model_tuned, history_tuned = train_tf(\n",
    "                model_name=\"nano_u\",\n",
    "                epochs=10,  # Shorter for tuning\n",
    "                batch_size=bs,\n",
    "                lr=lr,\n",
    "                config_path=\"config/config.yaml\"\n",
    "            )\n",
    "\n",
    "            # Store final validation metrics\n",
    "            final_val_iou = history_tuned.history['val_binary_iou'][-1]\n",
    "            results[f\"LR{lr}_BS{bs}\"] = {\n",
    "                'model': model_tuned,\n",
    "                'history': history_tuned,\n",
    "                'final_val_iou': final_val_iou\n",
    "            }\n",
    "            print(f\"Final validation IoU: {final_val_iou:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Training failed for LR={lr}, BS={bs}: {e}\")\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nHyperparameter Tuning Results:\")\n",
    "for config, result in results.items():\n",
    "    print(f\"{config}: Validation IoU = {result['final_val_iou']:.4f}\")\n",
    "\n",
    "# Find best configuration\n",
    "if results:\n",
    "    best_config = max(results.items(), key=lambda x: x[1]['final_val_iou'])\n",
    "    print(f\"\\nBest configuration: {best_config[0]} with IoU = {best_config[1]['final_val_iou']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad16552",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated various retraining experiments for the Nano-U project:\n",
    "\n",
    "1. **Basic Training**: Training Nano-U with default configuration\n",
    "2. **Custom Hyperparameters**: Modifying learning rate, batch size, and epochs\n",
    "3. **BU-Net Training**: Training the larger BU-Net model\n",
    "4. **Knowledge Distillation**: Using BU-Net as a teacher to improve Nano-U\n",
    "5. **Evaluation**: Running inference on trained models\n",
    "6. **Visualization**: Plotting training histories and metrics\n",
    "7. **Hyperparameter Tuning**: Systematic search over learning rates and batch sizes\n",
    "\n",
    "### Next Steps\n",
    "- Experiment with different data augmentations\n",
    "- Try different loss functions\n",
    "- Implement early stopping and learning rate scheduling\n",
    "- Add cross-validation for more robust evaluation\n",
    "- Experiment with model quantization for edge deployment\n",
    "\n",
    "Remember to check the `results/` directory for saved models and logs after training!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
