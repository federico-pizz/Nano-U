{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nano-U Training Workflow Example\n",
    "\n",
    "This notebook demonstrates the complete training pipeline for the Nano-U segmentation model, including:\n",
    "1. Dataset preparation\n",
    "2. Teacher model training (BU_Net)\n",
    "3. Student model training with knowledge distillation\n",
    "4. NAS monitoring for architecture analysis\n",
    "5. Quantization for edge deployment\n",
    "6. Evaluation and visualization\n",
    "\n",
    "**Runtime**: ~30-60 minutes on GPU (NVIDIA RTX 5060)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project to path\n",
    "PROJECT_ROOT = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# TensorFlow setup\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "\n",
    "# Custom imports\n",
    "from src.train import train\n",
    "from src.utils.config import load_config\n",
    "from src.utils import get_project_root\n",
    "\n",
    "print(\"\\nâœ“ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load project configuration\n",
    "config = load_config()\n",
    "\n",
    "# Display key settings\n",
    "print(\"ðŸ“‹ Configuration Loaded\")\n",
    "print(f\"\\nData Settings:\")\n",
    "print(f\"  Input shape: {config['data']['input_shape']}\")\n",
    "print(f\"  Normalization mean: {config['data']['normalization']['mean']}\")\n",
    "print(f\"  Normalization std: {config['data']['normalization']['std']}\")\n",
    "print(f\"  Train/Val/Test split: {config['data']['split']}\")\n",
    "\n",
    "print(f\"\\nModel Architectures:\")\n",
    "print(f\"  Nano_U filters: {config['models']['nano_u']['filters']}\")\n",
    "print(f\"  Nano_U bottleneck: {config['models']['nano_u']['bottleneck']}\")\n",
    "print(f\"  BU_Net filters: {config['models']['bu_net']['filters'][:3]}... (6 total)\")\n",
    "\n",
    "print(f\"\\nTraining Settings:\")\n",
    "print(f\"  Nano_U epochs: {config['training']['nano_u']['epochs']}\")\n",
    "print(f\"  Nano_U batch size: {config['training']['nano_u']['batch_size']}\")\n",
    "print(f\"  Distillation alpha: {config['training']['nano_u']['distillation']['alpha']}\")\n",
    "print(f\"  Distillation temperature: {config['training']['nano_u']['distillation']['temperature']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Dataset\n",
    "\n",
    "Run data preparation if not already done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if data is already prepared\n",
    "processed_dir = Path(get_project_root()) / 'data' / 'processed_data'\n",
    "\n",
    "if (processed_dir / 'train' / 'img').exists():\n",
    "    train_count = len(list((processed_dir / 'train' / 'img').glob('*.png')))\n",
    "    print(f\"âœ“ Data already prepared ({train_count} training samples)\")\n",
    "else:\n",
    "    print(\"ðŸ”„ Running data preparation...\")\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, str(Path(get_project_root()) / 'src' / 'prepare_data.py')],\n",
    "        cwd=str(get_project_root())\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ“ Data preparation complete\")\n",
    "    else:\n",
    "        print(\"âœ— Data preparation failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train Teacher Model (BU_Net)\n",
    "\n",
    "The teacher is a larger U-Net architecture that will guide the student model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸŽ“ Training Teacher Model (BU_Net)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train teacher\n",
    "teacher_model, teacher_history = train(\n",
    "    model_name=\"bu_net\",\n",
    "    epochs=50,  # Reduced for demo (use 100 in production)\n",
    "    batch_size=16,\n",
    "    lr=1e-4,\n",
    "    enable_nas_monitoring=False,  # Skip NAS for teacher\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ Teacher training complete\")\n",
    "print(f\"  Final validation IoU: {teacher_history.history['val_binary_iou'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train Student Model with Knowledge Distillation\n",
    "\n",
    "Now train the lightweight student model using the teacher as a guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ‘¶ Training Student Model (Nano_U) with Distillation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get teacher model path\n",
    "models_dir = Path(get_project_root()) / 'models'\n",
    "teacher_path = models_dir / 'bu_net.keras'\n",
    "\n",
    "# Train student with distillation\n",
    "student_model, student_history = train(\n",
    "    model_name=\"nano_u\",\n",
    "    epochs=50,  # Reduced for demo\n",
    "    batch_size=8,\n",
    "    lr=1e-4,\n",
    "    distill=True,\n",
    "    teacher_weights=str(teacher_path),\n",
    "    alpha=0.3,  # Favor distillation loss\n",
    "    temperature=4.0,  # Softer targets\n",
    "    enable_nas_monitoring=True,  # Enable NAS for analysis\n",
    "    nas_layers=['encoder_conv_0', 'encoder_conv_1', 'bottleneck'],\n",
    "    nas_log_dir='logs/nas_demo',\n",
    "    nas_csv_path='logs/nas_demo/nano_u_metrics.csv',\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ Student training complete\")\n",
    "print(f\"  Final validation IoU: {student_history.history['val_binary_iou'][-1]:.4f}\")\n",
    "print(f\"  Model saved to: {models_dir / 'nano_u.keras'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Compare Teacher vs Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model size comparison\n",
    "teacher_params = teacher_model.count_params()\n",
    "student_params = student_model.count_params()\n",
    "compression = (1 - student_params / teacher_params) * 100\n",
    "\n",
    "print(\"ðŸ“Š Model Comparison\")\n",
    "print(\"=\"*60)\n",
    "print(f\"BU_Net (Teacher):\")\n",
    "print(f\"  Parameters: {teacher_params:,} ({teacher_params/1e3:.1f}K)\")\n",
    "print(f\"\\nNano_U (Student):\")\n",
    "print(f\"  Parameters: {student_params:,} ({student_params/1e3:.1f}K)\")\n",
    "print(f\"\\nCompression: {compression:.1f}% parameter reduction\")\n",
    "print(f\"Speedup estimate: ~{teacher_params/student_params:.1f}x faster inference\")\n",
    "\n",
    "# Performance comparison\n",
    "print(f\"\\nPerformance Comparison:\")\n",
    "teacher_iou = teacher_history.history['val_binary_iou'][-1]\n",
    "student_iou = student_history.history['val_binary_iou'][-1]\n",
    "iou_gap = (teacher_iou - student_iou) / teacher_iou * 100\n",
    "\n",
    "print(f\"  BU_Net validation IoU: {teacher_iou:.4f}\")\n",
    "print(f\"  Nano_U validation IoU: {student_iou:.4f}\")\n",
    "print(f\"  Performance gap: {iou_gap:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(teacher_history.history['loss'], label='Teacher train', linewidth=2)\n",
    "axes[0].plot(teacher_history.history['val_loss'], label='Teacher val', linewidth=2, linestyle='--')\n",
    "axes[0].plot(student_history.history['loss'], label='Student train', linewidth=2)\n",
    "axes[0].plot(student_history.history['val_loss'], label='Student val', linewidth=2, linestyle='--')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training Loss Comparison')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# IoU curves\n",
    "axes[1].plot(teacher_history.history['binary_iou'], label='Teacher train', linewidth=2)\n",
    "axes[1].plot(teacher_history.history['val_binary_iou'], label='Teacher val', linewidth=2, linestyle='--')\n",
    "axes[1].plot(student_history.history['binary_iou'], label='Student train', linewidth=2)\n",
    "axes[1].plot(student_history.history['val_binary_iou'], label='Student val', linewidth=2, linestyle='--')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Binary IoU')\n",
    "axes[1].set_title('Segmentation Performance (IoU) Comparison')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Training curves saved to training_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: NAS Analysis\n",
    "\n",
    "Visualize redundancy metrics from the NAS monitoring callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load NAS metrics\n",
    "nas_csv = Path(get_project_root()) / 'logs' / 'nas_demo' / 'nano_u_metrics.csv'\n",
    "\n",
    "if nas_csv.exists():\n",
    "    nas_data = pd.read_csv(nas_csv)\n",
    "    \n",
    "    print(\"ðŸ“Š NAS Monitoring Results\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nLast epoch metrics:\")\n",
    "    last_row = nas_data.iloc[-1]\n",
    "    print(f\"  Redundancy score: {last_row['redundancy_score']:.4f}\")\n",
    "    print(f\"  Mean correlation: {last_row.get('mean_correlation', 'N/A')}\")\n",
    "    print(f\"  Condition number: {last_row.get('condition_number', 'N/A')}\")\n",
    "    print(f\"  Trace: {last_row.get('trace', 'N/A')}\")\n",
    "    \n",
    "    # Plot redundancy over time\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    if 'redundancy_score' in nas_data.columns:\n",
    "        ax.plot(nas_data.index, nas_data['redundancy_score'], linewidth=2, marker='o')\n",
    "        ax.axhline(y=0.7, color='r', linestyle='--', label='High redundancy threshold')\n",
    "        ax.axhline(y=0.3, color='g', linestyle='--', label='Low redundancy threshold')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Redundancy Score')\n",
    "    ax.set_title('Feature Redundancy Analysis During Training')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('nas_redundancy.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nâœ“ NAS analysis plots saved\")\n",
    "else:\n",
    "    print(\"âš  NAS CSV file not found. Skipping NAS analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Quantize Model for Edge Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”§ Quantizing Student Model to INT8\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Run quantization script\n",
    "result = subprocess.run(\n",
    "    [sys.executable, str(Path(get_project_root()) / 'src' / 'quantize.py'),\n",
    "     '--model-name', 'nano_u',\n",
    "     '--output', str(models_dir / 'nano_u_int8.tflite')],\n",
    "    cwd=str(get_project_root())\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    # Get file sizes\n",
    "    keras_size = (models_dir / 'nano_u.keras').stat().st_size / 1024  # KB\n",
    "    tflite_size = (models_dir / 'nano_u_int8.tflite').stat().st_size / 1024  # KB\n",
    "    \n",
    "    print(f\"\\nâœ“ Quantization complete\")\n",
    "    print(f\"  Keras model: {keras_size:.1f} KB\")\n",
    "    print(f\"  TFLite INT8: {tflite_size:.1f} KB\")\n",
    "    print(f\"  Size reduction: {(1 - tflite_size/keras_size)*100:.1f}%\")\n",
    "else:\n",
    "    print(\"âœ— Quantization failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Run Inference on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "\n",
    "# Load test images\n",
    "test_dir = Path(get_project_root()) / 'data' / 'processed_data' / 'test'\n",
    "test_images = sorted(glob.glob(str(test_dir / 'img' / '*.png')))[:5]  # Load 5 test samples\n",
    "\n",
    "print(f\"ðŸ”® Running Inference on {len(test_images)} Test Images\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare model for inference\n",
    "student_model = tf.keras.models.load_model(models_dir / 'nano_u.keras', compile=False)\n",
    "\n",
    "fig, axes = plt.subplots(len(test_images), 3, figsize=(12, 4*len(test_images)))\n",
    "if len(test_images) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for idx, img_path in enumerate(test_images):\n",
    "    # Load image and mask\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    mask_path = str(img_path).replace('/img/', '/mask/')\n",
    "    mask_gt = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Normalize and infer\n",
    "    img_norm = (img.astype(np.float32) / 255.0 - 0.5) / 0.5\n",
    "    logits = student_model(np.expand_dims(img_norm, 0), training=False)[0]\n",
    "    mask_pred = (1 / (1 + np.exp(-logits)) * 255).astype(np.uint8)  # Sigmoid + scale\n",
    "    \n",
    "    # Visualize\n",
    "    axes[idx, 0].imshow(img)\n",
    "    axes[idx, 0].set_title(f'Input Image {idx+1}')\n",
    "    axes[idx, 0].axis('off')\n",
    "    \n",
    "    axes[idx, 1].imshow(mask_gt, cmap='gray')\n",
    "    axes[idx, 1].set_title('Ground Truth')\n",
    "    axes[idx, 1].axis('off')\n",
    "    \n",
    "    axes[idx, 2].imshow(mask_pred.squeeze(), cmap='gray')\n",
    "    axes[idx, 2].set_title('Prediction')\n",
    "    axes[idx, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('inference_samples.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Inference visualizations saved to inference_samples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“ˆ Model Evaluation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Run evaluation\n",
    "result = subprocess.run(\n",
    "    [sys.executable, str(Path(get_project_root()) / 'src' / 'evaluate.py'),\n",
    "     '--model-name', 'nano_u',\n",
    "     '--out', str(Path(get_project_root()) / 'eval_results.json')],\n",
    "    cwd=str(get_project_root())\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    import json\n",
    "    with open(Path(get_project_root()) / 'eval_results.json') as f:\n",
    "        metrics = json.load(f)\n",
    "    print(f\"\\nâœ“ Evaluation complete\")\n",
    "    for key, value in metrics.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {key}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\nelse:\n",
    "    print(\"âš  Evaluation script not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've successfully completed the Nano-U training pipeline:\n",
    "\n",
    "âœ… **Teacher Model (BU_Net)**: Trained with ~180K parameters  \n",
    "âœ… **Student Model (Nano_U)**: Trained with knowledge distillation, ~41K parameters  \n",
    "âœ… **NAS Monitoring**: Analyzed feature redundancy during training  \n",
    "âœ… **Quantization**: Converted to INT8 TFLite for edge deployment  \n",
    "âœ… **Evaluation**: Benchmarked performance on test set  \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Deploy to ESP32-S3**:\n",
    "   ```bash\n",
    "   cd esp_flash\n",
    "   cargo build --release\n",
    "   espflash flash --monitor models/nano_u_int8.tflite\n",
    "   ```\n",
    "\n",
    "2. **Fine-tune Hyperparameters**:\n",
    "   - Adjust learning rate, batch size, distillation temperature\n",
    "   - Run NAS monitoring to detect overparameterization\n",
    "   - Implement architecture changes based on NAS recommendations\n",
    "\n",
    "3. **Integrate Custom Dataset**:\n",
    "   - See [`docs/CUSTOM_DATASET_INTEGRATION.md`](../docs/CUSTOM_DATASET_INTEGRATION.md)\n",
    "   - Update `config/config.yaml` with new dataset paths\n",
    "   - Re-run `src/prepare_data.py`\n",
    "\n",
    "4. **Performance Optimization**:\n",
    "   - Use NAS analysis to identify redundant layers\n",
    "   - Reduce model size for better edge deployment\n",
    "   - Measure inference latency on target hardware\n",
    "\n",
    "### References\n",
    "\n",
    "- [Main README](../README.md)\n",
    "- [NAS Technical Reference](../docs/NAS_README.md)\n",
    "- [Usage Examples](../docs/USAGE_EXAMPLES.md)\n",
    "- [Custom Dataset Integration](../docs/CUSTOM_DATASET_INTEGRATION.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
