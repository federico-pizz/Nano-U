# Nano-U: Ultra-Low-Power CNN for Microcontroller Real-Time Segmentation

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue)
![TensorFlow 2.21+](https://img.shields.io/badge/tensorflow-2.21+-blue)
![ESP32-S3](https://img.shields.io/badge/target-ESP32--S3-green)
![Research](https://img.shields.io/badge/status-research-orange)

> **Research Goal**: Real-time semantic segmentation for autonomous navigation on energy-constrained microcontrollers (ESP32-S3) with <100ms latency and <1W power consumption.

---

## ðŸ”¬ Overview

**Nano-U** investigates extreme CNN miniaturization for edge robotics:

| Feature | Description |
|---------|-------------|
| **Knowledge Distillation** | 180K â†’ 41K parameters (77% reduction) |
| **Depthwise Separable Convs** | Optimized for MCU memory constraints |
| **INT8 Quantization** | ~10KB final model size |
| **Microflow Compatible** | Rust-based `no_std` inference engine |

---

## ðŸš€ Quick Start

### Installation
```bash
git clone https://github.com/yourusername/Nano-U.git
cd Nano-U
python -m venv .venv-tf && source .venv-tf/bin/activate
pip install -r requirements.txt
```

### Run Full Pipeline
```bash
# Training â†’ Distillation â†’ Quantization â†’ Benchmarking
python scripts/run_pipeline.py --full
```

### Individual Commands
```bash
# List available experiments
python scripts/run_pipeline.py --list

# Run specific experiment
python scripts/run_pipeline.py --experiment quick_test

# Evaluate model
python src/evaluate.py --model-name nano_u
```

---

## ðŸ“ Project Structure

```
Nano-U/
â”œâ”€â”€ src/                    # Python source code
â”‚   â”œâ”€â”€ models/             # Model architectures (Nano-U, BU-Net)
â”‚   â”œâ”€â”€ utils/              # Utilities (metrics, callbacks)
â”‚   â”œâ”€â”€ train.py            # Training logic with distillation
â”‚   â”œâ”€â”€ nas.py              # Neural Architecture Search
â”‚   â”œâ”€â”€ evaluate.py         # Model evaluation
â”‚   â”œâ”€â”€ quantize_model.py   # INT8 quantization
â”‚   â””â”€â”€ benchmarks.py       # Performance benchmarking
â”œâ”€â”€ esp_flash/              # ESP32-S3 Rust inference (see esp_flash/README.md)
â”œâ”€â”€ config/                 # YAML configuration files
â”‚   â”œâ”€â”€ config.yaml         # Main training config
â”‚   â””â”€â”€ experiments.yaml    # Experiment definitions
â”œâ”€â”€ scripts/                # Pipeline automation
â”œâ”€â”€ models/                 # Saved models (.keras, .tflite)
â”œâ”€â”€ data/                   # Training datasets
â”œâ”€â”€ tests/                  # Unit tests
â””â”€â”€ notebooks/              # Jupyter notebooks
```

---

## ðŸ“Š Results

| Metric | Teacher (BU-Net) | Student (Nano-U) | Reduction |
|--------|------------------|------------------|-----------|
| Parameters | 180K | 41K | - |
| Model Size | ~720KB | ~164KB | **77%** |
| Quantized | â€” | ~10KB | **98.6%** |

---

## ðŸ› ï¸ Development

### Run Tests
```bash
pytest tests/ -v
```

### Configuration
Edit `config/config.yaml` for training parameters and `config/experiments.yaml` for experiment definitions.

---

## ðŸ“š Documentation

- **[API_REFERENCE.md](API_REFERENCE.md)** â€“ API and CLI documentation
- **[DEVELOPMENT.md](DEVELOPMENT.md)** â€“ Development guide and roadmap
- **[esp_flash/README.md](esp_flash/README.md)** â€“ ESP32-S3 deployment guide

---

## ðŸ“œ License

MIT License â€“ see [LICENSE](LICENSE)

---

**Last Updated**: 2026-02-07  
**Status**: Active Research
