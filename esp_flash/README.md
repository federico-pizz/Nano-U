# ESP32-S3 Embedded Inference (esp_flash)

Rust `no_std` project for running Nano-U inference on ESP32-S3 with stack usage analysis.

---

## ğŸ¯ Features

- **Microflow Inference** â€“ TFLite model execution via [`microflow-rs`](https://github.com/matteocarnelos/microflow-rs)
- **Stack Analysis** â€“ Runtime stack watermarking to measure peak usage
- **240MHz Operation** â€“ Maximum CPU clock for inference speed
- **Static Memory Allocation** â€“ Buffers in `.bss` to avoid stack overflow

---

## ğŸ“‹ Prerequisites

1. **ESP Rust Toolchain**
   ```bash
   # Install espup
   cargo install espup
   espup install
   
   # Source the environment
   source ~/export-esp.sh
   ```

2. **Python** (for analysis visualization)
   ```bash
   pip install matplotlib numpy
   ```

---

## ğŸš€ Quick Start

### Build & Flash
```bash
cd esp_flash

# Build analysis binary
cargo build --release --bin analysis

# Run full workflow (build â†’ flash â†’ capture â†’ visualize)
./run_analyzer.sh
```

### Manual Flash
```bash
espflash flash target/xtensa-esp32s3-none-elf/release/analysis --monitor
```

---

## ğŸ“ Structure

```
esp_flash/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ bin/
â”‚   â”‚   â”œâ”€â”€ analysis.rs     # Stack analysis binary (50 inference runs)
â”‚   â”‚   â””â”€â”€ main.rs         # Simple inference demo
â”‚   â””â”€â”€ lib.rs
â”œâ”€â”€ models/                  # TFLite models (nano_u.tflite)
â”œâ”€â”€ run_analyzer.sh          # Complete analysis workflow
â”œâ”€â”€ run_inference.py         # UART capture helper
â”œâ”€â”€ stack_analyzer.py        # Visualization generator
â”œâ”€â”€ Cargo.toml
â””â”€â”€ rust-toolchain.toml      # ESP Rust nightly config
```

---

## ğŸ”¬ Stack Analysis

The `analysis` binary uses **stack painting** to measure peak stack usage:

1. Fills unused stack with `0xAA` pattern before inference
2. Runs 50 inference iterations with real image data
3. Scans stack to find high-water mark
4. Reports `STACK_PEAK` and `STACK_TOTAL` via UART

### Output Example
```
Running Inference Iteration 1...
Inference done in 87 ms
STACK_PEAK:12456
STACK_TOTAL:32768
```

### Visualization
```bash
python stack_analyzer.py  # Generates stack_usage.png
```

---

## âš™ï¸ Configuration

### Cargo.toml Profiles
```toml
[profile.release]
opt-level = 3       # Maximum optimization
lto = 'fat'         # Link-time optimization
codegen-units = 1   # Better LLVM optimization
```

### Memory Configuration
Edit `.cargo/config.toml` to adjust stack size:
```toml
[env]
ESP_STACK_SIZE = "32768"  # 32KB stack
```

---

## ğŸ“– Additional Documentation

- **[RUST_ESP32S3_NOSTD.md](RUST_ESP32S3_NOSTD.md)** â€“ Detailed Rust `no_std` setup guide
- **[../README.md](../README.md)** â€“ Main project documentation

---

## ğŸ› Troubleshooting

| Issue | Solution |
|-------|----------|
| Stack overflow | for now just reducing the parameters of the model |
| Build fails | Run `source ~/export-esp.sh` first |
| No UART output | Check `/dev/ttyUSB0` permissions |
| Inference timeout | Watchdog is disabled; check model compatibility |

---

**Target**: ESP32-S3 @ 240MHz  
**Toolchain**: `esp` channel (nightly)  
**Framework**: `esp-hal` 1.0+
